<section id="evaluation" class="section">
  <h2>Evaluation Framework</h2>
  <p>
    CSTutorBench introduces a five-dimensional evaluation rubric tailored for educational quality:
  </p>
  <ol>
    <li><strong>Accuracy</strong>: Factual correctness and coverage</li>
    <li><strong>Clarity</strong>: Coherence and logical structure</li>
    <li><strong>Conciseness</strong>: Focus without redundancy</li>
    <li><strong>Personalization</strong>: Relevance to the student’s context</li>
    <li><strong>Engagement</strong>: Scaffolding and encouragement of active thinking</li>
  </ol>
  <p>
    Each response is scored from 1–5 per dimension, using a rubric that treats the human tutor’s reply as a high-quality reference (not a rigid ground truth).
    The scoring prompt is designed to reward educational value, even if the AI diverges in approach.
  </p>
  <p>
    See <a href="#" target="_blank" rel="noopener noreferrer">Appendix A in our paper</a> for the full scoring prompt.
  </p>
</section>